{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226eabdf",
   "metadata": {},
   "source": [
    "# 어노잉오렌지 전, 스노우 카메라 따라하기\n",
    "스노우카메라 리뷰로 좀더 기본적인 동영상 코드를 알아보고 경험해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddce732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, dlib, sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc355b4",
   "metadata": {},
   "source": [
    "## 1. 동영상에 bnd box 올려보기\n",
    "dlib 라이브러리를 이용하여 얼굴 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781593f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<_dlib_pybind11.fhog_object_detector at 0x10d41c030>,\n",
       " <_dlib_pybind11.shape_predictor at 0x10d52e7b0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resize (이미지 크기를 줄임)\n",
    "scaler = 0.3\n",
    "\n",
    "# initialize face detector and shape predictor\n",
    "detector = dlib.get_frontal_face_detector()  # 얼굴 디텍터 모듈 초기화\n",
    "# shape_pred.dat은 머신러닝으로 학습된 모델 \n",
    "predictor = dlib.shape_predictor('../shape_predictor_68_face_landmarks.dat')  # 얼굴 특징점 모듈 초기화\n",
    "\n",
    "detector, predictor   # objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27f0162b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_f/txsmx7r936jfbdwthf8dq_jm0000gn/T/ipykernel_91805/469290947.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# 윈도우 이름과 이미지 파일\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load video(동영상 파일 로드)\n",
    "# VideoCapture(0) - 파일 이름대신 0을 넣으면 웹캠\n",
    "cap = cv2.VideoCapture('girl.mp4')\n",
    "while True:\n",
    "    # read frame buffer from video\n",
    "    ret, img = cap.read()   # (boolean, np)\n",
    "#     print(img.shape)   # (1080, 1920, 3) (h!, w, c) \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # resize frame\n",
    "    # resize(img, dsize) 크기 조절(꼭 정수형으로 값을 받아야함)\n",
    "    img = cv2.resize(img, (int(img.shape[1] * scaler), int(img.shape[0] * scaler)))   # w, h 순서로 넣어야 함\n",
    "#     print(img.shape)    # (324, 576, 3) (h, w, c)\n",
    "    ori = img.copy()\n",
    "    \n",
    "    # 얼굴 찾기\n",
    "    faces = detector(img)   # rectangles라는 dlib 객체, 인덱싱 가능\n",
    "#     print(type(faces), faces)\n",
    "    face = faces[0]    # 여러얼굴이 나오니까 첫번째 얼굴만\n",
    "#     print(face)     # [(237, 83) (323, 170)], 좌상단 우하단\n",
    "    \n",
    "    # draw\n",
    "    # rectangle(img, 좌상단좌표, 우하단 좌표)\n",
    "#     print(type(face.left()), face.left())    # <class 'int'> 237\n",
    "    img = cv2.rectangle(img, \n",
    "                        pt1=(face.left(), face.top()),   # 다음 메소드를 통해 int로 반환가능\n",
    "                        pt2=(face.right(), face.bottom()),\n",
    "                        color=(255, 255, 255),           # 흰색\n",
    "                        thickness=2,\n",
    "                        lineType=cv2.LINE_AA\n",
    "                       )\n",
    "\n",
    "    # visualize\n",
    "    cv2.imshow('img', img)    # 윈도우 이름과 이미지 파일\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a934690",
   "metadata": {},
   "source": [
    "## 2. bnd box +  facial landmark 올려보기\n",
    "dlib 라이브러리를 이용하되, 얼굴 탐지는 라이브러리를 이용, 랜드마크 탐지는 사전 학습된 모델로 predictor로 만들어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f63e39ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/txsmx7r936jfbdwthf8dq_jm0000gn/T/ipykernel_91805/4091018938.py:41: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  center_x, center_y = np.mean(shape_2d, axis=0).astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "# resize (이미지 크기를 줄임)\n",
    "scaler = 0.3\n",
    "\n",
    "# initialize face detector and shape predictor\n",
    "detector = dlib.get_frontal_face_detector()  # 얼굴 디텍터 모듈 초기화\n",
    "# shape_pred.dat은 머신러닝으로 학습된 모델 \n",
    "predictor = dlib.shape_predictor('../shape_predictor_68_face_landmarks.dat')  # 얼굴 특징점 모듈 초기화\n",
    "\n",
    "# load video(동영상 파일 로드)\n",
    "# VideoCapture(0) - 파일 이름대신 0을 넣으면 웹캠\n",
    "cap = cv2.VideoCapture('girl.mp4')\n",
    "while True:\n",
    "    # read frame buffer from video\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # resize frame\n",
    "    # resize(img, dsize) 크기 조절(꼭 정수형으로 값을 받아야함)\n",
    "    img = cv2.resize(img, (int(img.shape[1] * scaler), int(img.shape[0] * scaler)))\n",
    "    ori = img.copy()\n",
    "    \n",
    "    # 얼굴 찾기\n",
    "    faces = detector(img)\n",
    "    face = faces[0]  # 여러얼굴이 나오니까 첫번째 얼굴만\n",
    "    \n",
    "    # 얼굴 특징점(facial landmark) 찾기\n",
    "    dlib_shape = predictor(img, face)   # dlib 객체\n",
    "    shape_2d = np.array([[p.x, p.y] for p in dlib_shape.parts()])  # dlib 객체를 68개 2차원 np 좌표로 변환\n",
    "#     print(type(shape_2d), shape_2d.shape, shape_2d)    #  <class 'numpy.ndarray'> (68, 2) [[246 100] ...[]]\n",
    "    \n",
    "    # 얻은 특징점으로 얼굴 size구하기(좌표 구하기)\n",
    "    # 좌상단 우하단\n",
    "    top_left = np.min(shape_2d, axis=0)    # 0차원끼리 비교\n",
    "    bottom_right = np.max(shape_2d, axis=0)\n",
    "#     print(top_left, bottom_right)    # [246  84] [328 172]\n",
    "    \n",
    "    # compute face center\n",
    "    # 랜드마크로 얼굴의 중심(좌표 구하기)\n",
    "    # 모든 특징점의 평균을 구하여 얼굴 중심을 구함, 정수형으로 변환필요\n",
    "    center_x, center_y = np.mean(shape_2d, axis=0).astype(np.int)\n",
    "    \n",
    "    \n",
    "    # draw\n",
    "    # rectangle(img, 좌상단좌표, 우하단 좌표)\n",
    "    img = cv2.rectangle(img, \n",
    "                        pt1=(face.left(), face.top()),\n",
    "                        pt2=(face.right(), face.bottom()),\n",
    "                        color=(255, 255, 255), # 흰색\n",
    "                        thickness=2,\n",
    "                        lineType=cv2.LINE_AA\n",
    "                       )\n",
    "    # 랜드마크를 원으로 표시\n",
    "    for s in shape_2d:\n",
    "        cv2.circle(img, center=tuple(s), radius=1, color=(255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # 랜드마크의 좌상단 우하단 크기 그리기\n",
    "    cv2.circle(img, center=tuple(top_left), radius=1, color=(255, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "    cv2.circle(img, center=tuple(bottom_right), radius=1, color=(255, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "    cv2.circle(img, center=(center_x, center_y), radius=1, color=(0, 0, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # visualize\n",
    "    cv2.imshow('img', img)    # 윈도우 이름과 이미지 파일\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a883bd6",
   "metadata": {},
   "source": [
    "## 3. 라이언얼굴로 바꾸기\n",
    "overlay_transparent란 사용자정의함수 만들어 동영상에 정적 img overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbddcb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay function\n",
    "def overlay_transparent(background_img, img_to_overlay_t, x, y, overlay_size=None):\n",
    "  bg_img = background_img.copy()\n",
    "  # convert 3 channels to 4 channels\n",
    "  if bg_img.shape[2] == 3:\n",
    "    bg_img = cv2.cvtColor(bg_img, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "  if overlay_size is not None:\n",
    "    img_to_overlay_t = cv2.resize(img_to_overlay_t.copy(), overlay_size)\n",
    "\n",
    "  b, g, r, a = cv2.split(img_to_overlay_t)\n",
    "\n",
    "  mask = cv2.medianBlur(a, 5)\n",
    "\n",
    "  h, w, _ = img_to_overlay_t.shape\n",
    "  roi = bg_img[int(y-h/2):int(y+h/2), int(x-w/2):int(x+w/2)]\n",
    "\n",
    "  img1_bg = cv2.bitwise_and(roi.copy(), roi.copy(), mask=cv2.bitwise_not(mask))\n",
    "  img2_fg = cv2.bitwise_and(img_to_overlay_t, img_to_overlay_t, mask=mask)\n",
    "\n",
    "  bg_img[int(y-h/2):int(y+h/2), int(x-w/2):int(x+w/2)] = cv2.add(img1_bg, img2_fg)\n",
    "\n",
    "  # convert 4 channels to 4 channels\n",
    "  bg_img = cv2.cvtColor(bg_img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "  return bg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56ea6154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/txsmx7r936jfbdwthf8dq_jm0000gn/T/ipykernel_91805/982654803.py:53: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  center_x, center_y = np.mean(shape_2d, axis=0).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "86\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "86\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "86\n",
      "87\n",
      "87\n",
      "86\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "87\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "87\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "89\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "88\n",
      "89\n",
      "88\n",
      "87\n",
      "89\n",
      "89\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "88\n",
      "89\n",
      "89\n",
      "88\n",
      "89\n",
      "89\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "88\n",
      "88\n",
      "89\n",
      "88\n",
      "89\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "88\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "89\n",
      "89\n",
      "88\n",
      "89\n",
      "88\n",
      "89\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "87\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "# resize (이미지 크기를 줄임)\n",
    "scaler = 0.3\n",
    "\n",
    "# initialize face detector and shape predictor\n",
    "detector = dlib.get_frontal_face_detector()  # 얼굴 디텍터 모듈 초기화\n",
    "# shape_pred.dat은 머신러닝으로 학습된 모델 \n",
    "predictor = dlib.shape_predictor('../shape_predictor_68_face_landmarks.dat')  # 얼굴 특징점 모듈 초기화\n",
    "\n",
    "# load video(동영상 파일 로드)\n",
    "# VideoCapture(0) - 파일 이름대신 0을 넣으면 웹캠\n",
    "cap = cv2.VideoCapture('girl.mp4')\n",
    "# load overlay image(라이언 이미지)\n",
    "overlay = cv2.imread('ryan_transparent.png', cv2.IMREAD_UNCHANGED) # 알파채널까지 함께 읽어야 함.(투명)\n",
    "# print(type(overlay), overlay.shape)    # <class 'numpy.ndarray'> (130, 129, 4) (h, w, c) 알파채널 포함 4\n",
    "\n",
    "\n",
    "while True:\n",
    "    # read frame buffer from video\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # resize frame\n",
    "    # resize(img, dsize) 크기 조절(꼭 정수형으로 값을 받아야함)\n",
    "    img = cv2.resize(img, (int(img.shape[1] * scaler), int(img.shape[0] * scaler)))\n",
    "    ori = img.copy()\n",
    "    \n",
    "    # 얼굴 찾기\n",
    "    faces = detector(img)\n",
    "    face = faces[0]  # 여러얼굴이 나오니까 첫번째 얼굴만\n",
    "    \n",
    "    # 얼굴 특징점(facial landmark) 찾기\n",
    "    dlib_shape = predictor(img, face)\n",
    "    shape_2d = np.array([[p.x, p.y] for p in dlib_shape.parts()])  # dlib 객체를 np로 변환\n",
    "    \n",
    "    # 얻은 특징점으로 얼굴 size구하기(좌표 구하기)\n",
    "    # 좌상단 우하단\n",
    "    top_left = np.min(shape_2d, axis=0)\n",
    "    bottom_right = np.max(shape_2d, axis=0)\n",
    "#     print(top_left, bottom_right)      # [246  84] [328 172]\n",
    "    \n",
    "    # compute face size\n",
    "    # 우하단에서 좌상단뺀 x, y길이의 가장 긴 값\n",
    "    face_size = max(bottom_right - top_left)     # 82 88\n",
    "    print(face_size)\n",
    "    # 라이언 얼굴 사이즈를 키우기 위해 1.8배 \n",
    "    face_size = int(np.mean(face_size) * 1.8)\n",
    "#     print(face_size)\n",
    "    \n",
    "    # compute face center\n",
    "    # 랜드마크로 얼굴의 중심(좌표 구하기)\n",
    "    # 모든 특징점의 평균을 구하여 얼굴 중심을 구함, 정수형으로 변환필요\n",
    "    center_x, center_y = np.mean(shape_2d, axis=0).astype(np.int)\n",
    "    \n",
    "    # draw overlay on face\n",
    "    # 라이언이미지를 센터x, y를 중심으로 넣고 overlay사이즈(얼굴의 가로세로중 가장큰 크기)만큼 resize해서 원본이미지에 넣어줌\n",
    "    result = overlay_transparent(ori, overlay, \n",
    "                                 center_x + 8, center_y - 25, \n",
    "                                 overlay_size=(face_size, face_size))\n",
    "    \n",
    "    \n",
    "    # draw\n",
    "    # rectangle(img, 좌상단좌표, 우하단 좌표)\n",
    "    img = cv2.rectangle(img, \n",
    "                        pt1=(face.left(), face.top()),\n",
    "                        pt2=(face.right(), face.bottom()),\n",
    "                        color=(255, 255, 255), # 흰색\n",
    "                        thickness=2,\n",
    "                        lineType=cv2.LINE_AA\n",
    "                       )\n",
    "    # 랜드마크를 원으로 표시\n",
    "    for s in shape_2d:\n",
    "        cv2.circle(img, center=tuple(s), radius=1, color=(255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # 랜드마크의 좌상단 우하단 크기 그리기\n",
    "    cv2.circle(img, center=tuple(top_left), radius=1, color=(255, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "    cv2.circle(img, center=tuple(bottom_right), radius=1, color=(255, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "    cv2.circle(img, center=(center_x, center_y), radius=1, color=(0, 0, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # visualize\n",
    "    cv2.imshow('img', img)    # 윈도우 이름과 이미지 파일\n",
    "    cv2.imshow('result', result)  # 라이언 이미지 오버랩 이미지\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1fb5be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
